# -*- coding: utf-8 -*-
"""implementation_EDA_Add_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lA9zbD3WlOYe0eAXHkFPh0h2TROMXJLJ

<h3>Step 1: Import libraries</h3>
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
import math
import warnings
warnings.filterwarnings('ignore')

"""<h3>Импорт данных</h3>"""

# Read dataset
train_data_path = os.path.abspath('train_data2 orr.csv')
test_data_path = os.path.abspath('testing_data2 orr.csv')

# merging two csv files
dataframe = pd.concat(map(pd.read_csv, [train_data_path, test_data_path]), ignore_index=True)

dataframe.head()

"""<h3>Анализ и предобработка</h3>

<b>Get required data</b>
"""

# Get required data
dataframe.drop(columns = ['Filename'], inplace=True)
#dataframe.drop(columns = ['Unnamed: 14'], inplace=True)
dataframe.head()

"""<b>Describe data</b>"""

# Describe data
dataframe.describe()

dataframe.info()

"""<b>Distribution of data</b>"""

# distribution
sns.displot(dataframe['PM2.5'])
sns.displot(dataframe['PM10'])
sns.displot(dataframe['O3'])
sns.displot(dataframe['CO'])
sns.displot(dataframe['SO2'])
sns.displot(dataframe['NO2'])

"""<b>Label encoding</b>

"""

# Label encoding
le = LabelEncoder()
dataframe['Location'] = le.fit_transform(dataframe['Location'])
dataframe['Hour'] = le.fit_transform(dataframe['Hour'])
#dataframe['AQI_Class'] = le.fit_transform(dataframe['AQI_Class'])

dataframe.head()

"""<b>Drop insignificant data</b>


"""

# Drop Year and Month columns
dataframe.drop(columns=['Year'], inplace=True)
dataframe.drop(columns=['Month'], inplace=True)

# Review missing data
print(dataframe.isnull().sum())

# Eliminate rows with at least three missing values
dataframe = dataframe.dropna(thresh=3)
dataframe.head()

# Review rows with remaining missing values
missing_O3_indices = [i for i,v in enumerate(dataframe['O3'].isnull()) if v==True]
missing_CO_indices = [i for i,v in enumerate(dataframe['CO'].isnull()) if v==True]
missing_SO2_indices = [i for i,v in enumerate(dataframe['SO2'].isnull()) if v==True]
missing_NO2_indices = [i for i,v in enumerate(dataframe['NO2'].isnull()) if v==True]
all_missing_indices = list(set(missing_O3_indices + missing_CO_indices + missing_SO2_indices + missing_NO2_indices))
print("Number of missing SO2 data is", len(all_missing_indices))
missingData = dataframe.iloc[all_missing_indices]

# Inpute missing values for SO2 based on the mean of similar rows
for index, row in missingData.iterrows():
    o3 = row[6]
    co = row[7]
    so2 = row[8]
    no2 = row[9]
    if math.isnan(row[6]): dataframe.at[index, 'O3'] = dataframe.loc[:, 'O3'].mean()
    if math.isnan(row[7]): dataframe.at[index, 'CO'] = dataframe.loc[:, 'CO'].mean()
    if math.isnan(row[8]): dataframe.at[index, 'SO2'] = dataframe.loc[:, 'SO2'].mean()
    if math.isnan(row[9]): dataframe.at[index, 'NO2'] = dataframe.loc[:, 'NO2'].mean()

# Review missing data
print(dataframe.isnull().sum())

plt.figure(figsize=(13, 4))
sns.boxplot(data=dataframe, x="AQI_Class", y="NO2")
plt.title("NO2 выбросы")
plt.show()
plt.figure(figsize=(13, 4))
sns.boxplot(data=dataframe, x="AQI_Class", y="PM2.5")
plt.title("PM2.5 выбросы")
plt.show()
plt.figure(figsize=(13, 4))
sns.boxplot(data=dataframe, x="AQI_Class", y="PM10")
plt.title("PM10 выбросы")
plt.show()
plt.figure(figsize=(13, 4))
sns.boxplot(data=dataframe, x="AQI_Class", y="O3")
plt.title("O3 выбросы")
plt.show()
plt.figure(figsize=(13, 4))
sns.boxplot(data=dataframe, x="AQI_Class", y="CO")
plt.title("CO выбросы")
plt.show()
plt.figure(figsize=(13, 4))
sns.boxplot(data=dataframe, x="AQI_Class", y="SO2")
plt.title("SO2 выбросы")
plt.show()

sns.pairplot(dataframe, hue="AQI_Class")
plt.show()

"""***Первичный корреляционный анализ***

**SMOTE, ADASYN**
"""

import pandas as pd
from imblearn.over_sampling import SMOTE, ADASYN
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Removing unnecessary columns
df2 = dataframe.drop(columns=['Location', 'Day', 'Hour'])

# Handling missing values
df2 = df2.dropna()

# Encoding categorical feature
le = LabelEncoder()
df2['AQI_Class'] = le.fit_transform(df2['AQI_Class'])

# Splitting features and target variable
X = df2.drop(columns=['AQI_Class'])
y = df2['AQI_Class']

# Splitting into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Applying SMOTE
smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X_train, y_train)

# Applying ADASYN
adasyn = ADASYN(random_state=42)
X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)

# Converting back to DataFrame
df_smote = pd.DataFrame(X_smote, columns=X.columns)
df_smote['AQI_Class'] = y_smote

df_adasyn = pd.DataFrame(X_adasyn, columns=X.columns)
df_adasyn['AQI_Class'] = y_adasyn

# Saving the results
df_smote.to_csv('air_pollution_data_balanced_smote.csv', index=False)
df_adasyn.to_csv('air_pollution_data_balanced_adasyn.csv', index=False)

print("Files with balanced data have been saved!")

df_encoded1 = pd.get_dummies(dataframe, columns=['Location', 'Hour', 'AQI_Class'], drop_first=True)

df_encoded1.corr()
sns.heatmap(df_encoded.corr())

pearson_corr = df_encoded1.corr(method='pearson')
spearman_corr = df_encoded1.corr(method='spearman')
#  heatmap
def plot_correlation_matrix(corr_matrix, title):
    plt.figure(figsize=(6,5))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
    plt.title(title)
    plt.show()

# Matrix Visualisation
plot_correlation_matrix(pearson_corr, "Correlation matrix (Pearson)")
plot_correlation_matrix(spearman_corr, "Correlation matrix (Spearman)")





"""**Z-score, IQR**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import zscore

# Оставляем только числовые данные
numeric_df = df.select_dtypes(include=[np.number])

# Функция для поиска выбросов по Z-score
def detect_outliers_zscore(data, threshold=3):
    z_scores = np.abs(zscore(data))
    return z_scores > threshold

# Функция для поиска выбросов по IQR
def detect_outliers_iqr(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    return (data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))

# Вычисление выбросов
outliers_zscore = numeric_df.apply(detect_outliers_zscore)
outliers_iqr = numeric_df.apply(detect_outliers_iqr)

# Визуализация выбросов (Z-score)
plt.figure(figsize=(10, 5))
sns.heatmap(outliers_zscore, cmap='coolwarm', cbar=False, xticklabels=numeric_df.columns)
plt.xticks(rotation=45)
plt.title("Outlier Analysis using Z-score")
plt.show()

# Визуализация выбросов (IQR)
plt.figure(figsize=(10, 5))
sns.boxplot(data=numeric_df)
plt.xticks(rotation=45)
plt.title("Outlier Analysis using IQR")
plt.show()

"""*** Корреляционный анализ и прверка статистических гипотез после обработки***"""

df2.corr()
sns.heatmap(df2.corr())

pearson_corr = df2.corr(method='pearson')
spearman_corr = df2.corr(method='spearman')
#  heatmap
def plot_correlation_matrix(corr_matrix, title):
    plt.figure(figsize=(6,5))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
    plt.title(title)
    plt.show()

# Matrix Visualisation
plot_correlation_matrix(pearson_corr, "Correlation matrix (Pearson)")
plot_correlation_matrix(spearman_corr, "Correlation matrix (Spearman)")

import numpy as np
import pandas as pd
import scipy.stats as stats
import seaborn as sns
import matplotlib.pyplot as plt

group_0 = df2[df2['AQI_Class'] == 0]['AQI']
group_1 = df2[df2['AQI_Class'] == 1]['AQI']

t_stat, p_value_ttest = stats.ttest_ind(group_0, group_1, equal_var=False)  # Welch’s t-test

# ANOVA: comparing AQI between three or more AQI_Class categories
anova_stat, p_value_anova = stats.f_oneway(
    df[df['AQI_Class'] == 0]['AQI'],
    df[df['AQI_Class'] == 1]['AQI'],
    df[df['AQI_Class'] == 2]['AQI'],
    df[df['AQI_Class'] == 3]['AQI']
)

# χ² test: checking the dependence of AQI_Class on pollution level (categorizing PM2.5)
df2['PM2.5_Category'] = pd.qcut(df2['PM2.5'], q=2, labels=['Low', 'High'])  # Creating categories

contingency_table = pd.crosstab(df2['AQI_Class'], df['PM2.5_Category'])
chi2_stat, p_value_chi2, dof, expected = stats.chi2_contingency(contingency_table)

# Visualization of distributions
plt.figure(figsize=(12, 4))

# t-test
plt.subplot(1, 3, 1)
sns.histplot(group_0, color='blue', kde=True, label='AQI_Class 0', alpha=0.6)
sns.histplot(group_1, color='red', kde=True, label='AQI_Class 1', alpha=0.6)
plt.axvline(np.mean(group_0), color='blue', linestyle='dashed', linewidth=2)
plt.axvline(np.mean(group_1), color='red', linestyle='dashed', linewidth=2)
plt.title(f't-test')
plt.legend()

# ANOVA
plt.subplot(1, 3, 2)
sns.boxplot(x='AQI_Class', y='AQI', data=df)
plt.title(f'ANOVA')

# χ² test (frequency table)
plt.subplot(1, 3, 3)
sns.heatmap(contingency_table, annot=True, cmap='coolwarm', fmt='d', cbar=False)
plt.title(f'χ² test')

plt.tight_layout()
plt.show()

"""**Факторный анализ**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import FactorAnalysis
from sklearn.preprocessing import StandardScaler

# Selecting numerical variables for analysis
features = ['AQI', 'PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3']  # Add other variables if available
df_features = df2[features].dropna()  # Removing missing values

# Standardizing the data
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# Selecting the number of factors
fa = FactorAnalysis(n_components=3)  # Specify the required number of factors
fa.fit(df_scaled)

# Displaying factor loadings
loadings = pd.DataFrame(fa.components_.T, index=features, columns=[f'Factor {i+1}' for i in range(3)])
print("Factor Loadings:")
print(loadings)

# Visualizing the factor loadings matrix
plt.figure(figsize=(10, 6))
sns.heatmap(loadings, annot=True, cmap='coolwarm', center=0)
plt.title('Factor Loadings Heatmap')
plt.show()

"""**Снижение размерности**"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler

# Select features and target variable
X = dataframe.drop(columns=['AQI_Class'])  # Features
y = dataframe['AQI_Class']  # Classes

# Data standardization (important for PCA and t-SNE)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 1. PCA: Dimensionality reduction to 2D
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# 2. t-SNE: Nonlinear dimensionality reduction to 2D
tsne = TSNE(n_components=2, random_state=42, perplexity=5)
X_tsne = tsne.fit_transform(X_scaled)

# Visualization of PCA results
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='coolwarm', s=100)
plt.title('PCA: Dimensionality Reduction to 2D')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# Visualization of t-SNE results
plt.subplot(1, 2, 2)
sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=y, palette='coolwarm', s=100)
plt.title('t-SNE: Dimensionality Reduction to 2D')
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')

plt.tight_layout()
plt.show()

# Evaluation of explained variance in PCA
explained_variance = pca.explained_variance_ratio_
print(f"Explained variance ratio (PCA): {explained_variance[0]:.2%}, {explained_variance[1]:.2%}")
print(f"Total PCA explains {sum(explained_variance) * 100:.2f}% of the information")

